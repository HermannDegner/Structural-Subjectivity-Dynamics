# SSD：整合慣性×ランダム接続 — 跳躍の最小ハイブリッドモデル（対数整合拡張版）

## 0. 目的と要約

- **目的**：整合（決定論・省エネ）と、跳躍（確率論・接続拡張）を単一の時間発展で統合する
- **要約**：
  - 既存の整合回路（オーム則アナロジー）に、未処理圧リザーバ $E$ を導入
  - **対数整合層（Log-Alignment）** により広範な動的範囲での安定性を確保
  - $E$ が閾値を超えると**制約付きランダム接続**でネットワークを再配線（跳躍）
  - 跳躍後は放熱（$E$ 減衰）と慣性調整で再び整合へ
  - 硬直化すれば温度 $T \uparrow$ で探索を増やす

**v2.0の新機能：** Weber–Fechner対応の対数整合により、極端な意味圧入力での破綻を防ぎ、飽和抑制と適応的感度調整を実現

---

## 1. 状態と変数

### 1.1. 基本構造

- **構造ネットワーク**：$G = (\mathcal{S}, \mathcal{E}, w)$
  - $\mathcal{S}$：ノード集合（概念・戦術）
  - $\mathcal{E}$：エッジ集合（接続関係）
  - $w_{ij}$：エッジ重み

### 1.2. 動的変数

- **整合慣性**：$\kappa_{ij}(t)$ - 経路の通りやすさ／記憶
- **入力（意味圧）**：$p(t)$ - 課題ベクトル or スカラー
- **変換意味圧**：$\hat{p}(t)$ - 対数整合により変換された意味圧（オプション）
- **未処理圧リザーバ**：$E(t)$ - 整合不能の蓄積（"熱"）
- **温度**：$T(t)$ - 探索の強さ
- **適応ゲイン**：$\alpha_t$ - 対数整合の動的感度調整（オプション）

---

## 1a. 対数整合層（Log-Alignment Layer）

### 1a.1. 理論的背景

極端な意味圧（高難易度課題、強刺激）が入力された際、線形応答では：
- 整合流 $j$ が過大になり、慣性 $\kappa$ が急激に変動
- 未処理圧 $E$ が爆発的に蓄積
- 不要な跳躍が頻発

**Weber–Fechner対応の対数整合**により、これらを抑制します。

### 1a.2. 対数変換の定義

$$\hat{p}_i(t) = \operatorname{sign}(p_i) \cdot \frac{\log(1 + \alpha_t |p_i|)}{\log b}$$

**適応ゲイン**（明暗順応のアナロジー）：

$$\alpha_t = \frac{\alpha_0}{\epsilon + \mathrm{EMA}_\tau(\|p\|)}$$

**パラメータ：**
- $b$：対数底（既定は $e$）
- $\alpha_0$：初期ゲイン（既定は $1.0$）
- $\tau$：EMA時定数（既定は $50$）
- $\epsilon$：数値安定化定数（$10^{-6}$）

### 1a.3. 使用判断

**対数整合を有効化すべき場合：**
- 意味圧の動的範囲が広い（難易度が10倍以上変動）
- 高負荷時に破綻が観測される
- リアルタイム適応が必要（ゲーム、対話システム）

**標準モデルで十分な場合：**
- 意味圧が安定した範囲内
- 計算コストを最小化したい
- シンプルな線形応答で十分

---

## 2. 連続部：整合ダイナミクス

### 2.1. 通りやすさの定義

$$G_{ij}(t) = G_{0,ij} + g \cdot \kappa_{ij}(t)$$

**パラメータ説明：**

- $G_{0,ij}$：基本通りやすさ
- $g > 0$：慣性の影響係数

### 2.2. 整合流（ネットワーク版オーム則）

**標準版（線形応答）：**

$$j_{ij}(t) = G_{ij}(t) \cdot a_{ij}(t)$$

**対数整合版（非線形応答）：**

$$j_{ij}(t) = G_{ij}(t) \cdot \hat{a}_{ij}(t)$$

ここで、

$$a_{ij}(t) = \langle\phi_i, p(t)\rangle - \langle\phi_j, p(t)\rangle$$

$$\hat{a}_{ij}(t) = \langle\phi_i, \hat{p}(t)\rangle - \langle\phi_j, \hat{p}(t)\rangle$$

**簡略版：**

- 標準：$a_{ij}(t) = p(t)$
- 対数整合：$\hat{a}_{ij}(t) = \hat{p}(t)$

### 2.3. 整合仕事（正味）

**標準版：**

$$\dot{W}_{\text{align}}(t) = \sum_{(i,j)} \left( p(t) \cdot j_{ij} - \rho \cdot j_{ij}^2 \right)$$

**対数整合版：**

$$\dot{W}_{\text{align}}(t) = \sum_{(i,j)} \left( \hat{p}(t) \cdot j_{ij} - \rho \cdot j_{ij}^2 \right)$$

**パラメータ説明：**

- 第1項：入力パワー
- 第2項：抵抗損失（$\rho > 0$）

### 2.4. 慣性更新（学習・忘却）

**標準版：**

$$\frac{d\kappa_{ij}}{dt} = \eta \left[ p(t) \cdot j_{ij} - \rho \cdot j_{ij}^2 \right] - \lambda(\kappa_{ij} - \kappa_{\min})$$

**対数整合版：**

$$\frac{d\kappa_{ij}}{dt} = \eta \left[ \hat{p}(t) \cdot j_{ij} - \rho \cdot j_{ij}^2 \right] - \lambda(\kappa_{ij} - \kappa_{\min})$$

**パラメータ説明：**

- $\eta > 0$：学習率
- $\lambda > 0$：忘却率
- $\kappa_{\min} \geq 0$：慣性の下限値

---

## 3. 未処理圧の蓄積（整合不能の計上）

**標準版：**

$$\frac{dE}{dt} = \alpha \left[ \|p(t)\| - \|J(t)\| \right]_+ - \beta E$$

**対数整合版（スケール調整）：**

$$\frac{dE}{dt} = \alpha \left[ \|p(t)\| - \zeta \cdot \|J(t)\| \right]_+ - \beta E$$

**記号説明：**

- $\|J(t)\| := \sqrt{\sum_{ij} j_{ij}^2}$：総整合流のノルム
- $[x]_+ := \max(x, 0)$：正の部分のみ
- $\alpha > 0$：蓄積係数
- $\beta > 0$：自然減衰係数
- $\zeta$：スケール整合係数（対数整合使用時）

**$\zeta$ の推定**（対数整合使用時）：

$$\zeta \approx \frac{1}{\log b} \cdot \|G_0 + g\kappa\|_{\text{op}}$$

実務では起動後のEMAまたは学習で自動調整。既定値：$\zeta = 1.0$（自動推定推奨）。

**物理的意味：** 整合が追いつかない差分を"熱"として貯蔵。対数整合時はスケールの不一致を $\zeta$ で補正。

---

## 4. 跳躍トリガ（確率的発火）

### 4.1. 発火強度（ポアソン過程）

$$h(t) = h_0 \exp\left(\frac{E(t) - \Theta(t)}{\gamma}\right)$$

### 4.2. 動的閾値

$$\Theta(t) = \Theta_0 + a_1 \bar{\kappa}(t) - a_2 F(t)$$

**パラメータ説明：**
- $\bar{\kappa}(t) = \frac{1}{|\mathcal{E}|} \sum_{ij} \kappa_{ij}(t)$：平均慣性
- $F(t)$：疲労などの可逆指標
- $a_1 > 0$：慣性が高いほど跳びにくい
- $a_2 > 0$：疲労が高いほど跳びやすい

### 4.3. 発火確率

微小時間 $\Delta t$ での発火確率：

$$P_{\text{jump}}(\Delta t) = 1 - \exp(-h(t) \cdot \Delta t)$$

---

## 5. 跳躍：制約付きランダム接続（構造依存＋ノイズ）

### 5.1. 候補選択の確率分布

候補集合 $\mathcal{C}$ から、新規接続先 $k$ を以下の確率で選択：

$$\pi(k \mid s, t) \propto \exp\left(\frac{\text{sim}(s,k) + \xi_k}{T(t)}\right)$$

**成分説明：**
- $\text{sim}(s,k)$：構造依存の類似度
- $\xi_k \sim \mathcal{N}(0, \sigma^2)$：ガウスノイズ
- $T(t)$：探索温度

### 5.2. 探索温度の動的調整

$$T(t) = T_0 + c_1 E(t) - c_2 H(\pi_{t^-})$$

**パラメータ説明：**
- $T_0 > 0$：基本温度
- $c_1 > 0$：熱による温度上昇
- $c_2 > 0$：エントロピー低下による温度上昇
- $H(\pi)$：政策エントロピー

### 5.3. 接続の追加・強化

選ばれたエッジの更新：

$$w_{sk} \leftarrow w_{sk} + \Delta w$$
$$\kappa_{sk} \leftarrow \kappa_{sk} + \Delta \kappa^{(+)}$$

### 5.4. 硬直ほぐし（過飽和経路の微緩和）

上位 $q\%$ の主経路に対して：

$$\kappa_{ij} \leftarrow \kappa_{ij} - \epsilon \cdot \mathbb{I}\{j_{ij} \text{が上位} q\% \text{に該当}\}$$

### 5.5. 放熱

$$E \leftarrow c_0 E \quad (0 \leq c_0 < 1)$$

---

## 6. 硬直—創発バランサ

### 6.1. 硬直度の測定

政策のエントロピー：

$$H(\pi) = -\sum_k \pi(k) \log \pi(k)$$

エントロピーが低下しすぎた場合、温度 $T$ を底上げ。

### 6.2. 探索ノイズ（$\varepsilon$-greedy）

$$\varepsilon(t) = \varepsilon_0 + d_1 E - d_2 \bar{\kappa}$$

確率 $\varepsilon(t)$ で完全ランダム接続を混入。

**パラメータ説明：**
- $\varepsilon_0$：基本探索率
- $d_1 > 0$：熱による探索増加
- $d_2 > 0$：慣性による探索減少

---

## 7. 観測指標（ダッシュボード）

### 7.1. 主要KPI

| 指標 | 数式 | 意味 |
|------|------|------|
| **整合効率** | $\eta_{\text{align}} = \frac{\|J\|}{\|p\|}$ | 入力に対する有効出力の割合 |
| **放熱率** | $-\frac{dE}{dt}$ | 熱の減少速度 |
| **政策エントロピー** | $H(\pi) = -\sum_k \pi_k \log \pi_k$ | 探索の多様性 |
| **新規接続率** | $\frac{|\delta\mathcal{E}|}{\Delta t}$ | 単位時間あたりの新接続数 |
| **創造歩留まり** | $\frac{\text{持続する新接続}}{\text{総新接続}}$ | 新接続の定着率 |

### 7.2. デバッグ用補助指標

- 平均慣性：$\bar{\kappa}(t)$
- 慣性分散：$\text{Var}[\kappa_{ij}]$
- 接続密度：$\frac{|\mathcal{E}|}{|\mathcal{S}|^2}$

---

## 8. 擬似コード（逐次更新）

```python
# === 初期化 ===
log_align_enabled = True  # 対数整合を使用
if log_align_enabled:
    log_layer = LogAlignmentLayer(alpha0=1.0, base=np.e, ema_tau=50)
    zeta = 1.0  # 自動推定される

for t in range(T_max):
    # === 対数整合変換（オプション） ===
    if log_align_enabled:
        p_hat, alpha_t = log_layer.transform(p)
    else:
        p_hat = p
        alpha_t = None
    
    # === 整合ステップ（決定論的） ===
    # 1. 整合流の計算
    for (i, j) in edges:
        a_ij = p_hat if log_align_enabled else p  # 簡略版
        j_ij = (G0[i,j] + g * kappa[i,j]) * a_ij
    
    # 2. 整合仕事と慣性更新
    for (i, j) in edges:
        work = p_hat * j_ij - rho * j_ij**2 if log_align_enabled else p * j_ij - rho * j_ij**2
        kappa[i,j] += eta * work - lambda_f * (kappa[i,j] - kappa_min)
    
    # 3. 未処理圧の蓄積（スケール調整）
    J_norm = norm(J)
    if log_align_enabled:
        # zetaの自動推定（EMA）
        zeta = 0.95 * zeta + 0.05 * (norm(p_hat) / (J_norm + 1e-6))
        residual = max(norm(p) - zeta * J_norm, 0)
    else:
        residual = max(norm(p) - J_norm, 0)
    
    E += alpha * residual - beta * E

    # === 跳躍判定（確率論的） ===
    # 4. 閾値と発火強度
    Theta = Theta0 + a1 * mean(kappa) - a2 * F
    h = h0 * exp((E - Theta) / gamma)
    
    # 5. 跳躍実行
    if random() < (1 - exp(-h * dt)):
        # 探索温度の計算
        T_explore = T0 + c1 * E - c2 * entropy(policy_prev)
        
        # 制約付きランダム接続
        candidates = get_candidates(G, context)
        k = sample_from_softmax(
            [(sim(s, k) + noise()) / T_explore for k in candidates]
        )
        
        # エッジの追加・強化
        add_or_boost_edge(G, s, k, delta_w)
        kappa[s, k] += delta_kappa_plus
        
        # 硬直ほぐし
        top_edges = get_top_q_percent_edges_by_flow(G)
        for edge in top_edges:
            kappa[edge] -= epsilon_relax
        
        # 放熱
        E *= c0

    # === ε-greedy完全ランダム接続 ===
    epsilon = epsilon0 + d1 * E - d2 * mean(kappa)
    if random() < epsilon:
        randomly_add_or_rewire_weak_edge(G)
    
    # === ログ記録（デバッグ用） ===
    if log_align_enabled:
        log_metrics(t, E, J_norm, zeta, alpha_t, entropy(policy))
    else:
        log_metrics(t, E, J_norm, entropy(policy))
```

---

## 9. 実験プロトコル（最小セット）

### 9.1. 基本動作確認

1. **単一課題テスト**
   - 固定ベクトル $p$ を入力
   - $E$, $T$, $H(\pi)$ の時間発展を観察

2. **課題系列テスト**  
   - 局所相関の低い $p_t$ を連続投入
   - 跳躍頻度と整合効率のトレードオフを計測

### 9.2. 対数整合の検証（オプション）

3. **飽和抑制テスト**
   - 極端な意味圧（$\|p\| \gg$ 通常）を投入
   - 標準版vs対数整合版で $E$ の蓄積速度を比較
   - 期待結果：対数整合版で $E$ 爆発が抑制される

4. **適応ゲインテスト**
   - 意味圧の平均強度を段階的に変化
   - $\alpha_t$ の追従を確認
   - 期待結果：高強度環境で $\alpha_t \downarrow$、低強度環境で $\alpha_t \uparrow$

5. **スケール整合テスト**
   - $\zeta$ の自動推定が収束するか確認
   - 対数空間と物理空間での整合効率の一貫性をチェック

### 9.3. パラメータ調整実験

6. **硬直化テスト**
   - $\lambda \downarrow$（忘却遅延）で硬直を意図的に誘発  
   - $T$ 制御の効果を検証

7. **創造歩留まり測定**
   - 新規接続の持続率（$\kappa$ 増加継続）を計測
   - 分布（近傍 vs 遠方接続）を分析

---

## 10. 応用・解釈

### 10.1. 心理現象のモデル化

- **閃き**：$E$ が閾値超え → 遠方ノードと接続 → 新経路が学習で固定
- **暴走**：$T$ 過大や $\rho$ 低下 → ノイズ優位 → 整合効率低下・熱暴走
- **冷静性**：$\beta \uparrow$, $c_2 \uparrow$ → 必要な跳躍のみを残すバランス調整
- **適応的知覚**：対数整合による $\alpha_t$ の自動調整 → 明暗順応・音量順応のモデル化
- **過負荷への耐性**：飽和抑制により、極端なストレス下でも破綻せず機能維持

### 10.2. 教育・訓練への応用

- **適応的難易度**：$E$ レベルに応じた課題提示、対数整合により広範な難易度に対応
- **創造性促進**：意図的な $T$ 制御による探索誘導
- **燃え尽き防止**：$\beta$ パラメータによる適切な休息設計、対数整合で過負荷を自動緩和
- **個別最適化**：$\alpha_t$ の追跡により学習者の感度特性を把握

### 10.3. ゲームAI・対話システムへの応用

- **動的難易度調整**：プレイヤーの熟練度（$\kappa$）に応じた課題生成
- **驚きと納得の両立**：跳躍による予測不能性と整合による一貫性の共存
- **リアルタイム適応**：対数整合により、初心者から上級者まで同一システムで対応
- **エンゲージメント維持**：$E$ を適正範囲に保ち、退屈と過負荷を回避

---

## 11. パラメータチューニングガイド

### 11.1. 典型的な問題と対策

| 問題症状 | 可能性のある原因 | 推奨調整 |
|----------|----------------|----------|
| **硬直して単調** | 探索不足 | $T_0 \uparrow$, $\sigma \uparrow$, $\varepsilon_0 \uparrow$ |
| **暴走して雑** | 探索過多 | $T_0 \downarrow$, $\rho \uparrow$, $c_2 \uparrow$ |
| **過跳躍** | 閾値が低い | $\gamma \uparrow$, $\Theta_0 \uparrow$, $a_1 \uparrow$ |
| **考えすぎで動かない** | 基本流量不足 | $g \uparrow$, $G_0 \uparrow$, $\beta_E \uparrow$ |

### 11.2. パラメータの目安（ゲーム向け）

| 記号 | 既定値 | 範囲 | 意味 |
|------|--------|------|------|
| $G_0$ | 0.5 | 0.1–1.0 | 基本通りやすさ |
| $g$ | 0.7 | 0.2–1.5 | $\kappa$ の影響係数 |
| $\eta$ | 0.3 | 0.1–0.5 | 学習率 |
| $\lambda$ | 0.02 | 0.005–0.05 | 忘却率 |
| $\alpha$ | 0.6 | 0.2–1.0 | 熱の蓄積係数 |
| $\beta_E$ | 0.15 | 0.05–0.3 | 熱の自然減衰 |
| $\Theta_0$ | 1.0 | 0.5–2.0 | 基本閾値 |
| $h_0$ | 0.2 | 0.05–0.5 | 跳躍のベース強度 |
| $\gamma$ | 0.8 | 0.4–1.5 | 発火曲線の鋭さ |
| $T_0$ | 0.3 | 0.1–0.7 | 探索温度の下限 |
| $\sigma$ | 0.2 | 0.05–0.5 | ノイズ幅 |

### 11.3. 対数整合パラメータ（オプション）

| 記号 | 既定値 | 範囲 | 意味 |
|------|--------|------|------|
| `log_align_enabled` | False | True/False | 対数整合の有効化 |
| $\alpha_0$ | 1.0 | 0.5–2.0 | 原点傾き（小信号ゲイン） |
| $b$ | $e$ | $e$ or $10$ | 対数底（$e$:自然、$10$:dB） |
| $\tau$ | 50 | 20–200 | EMA時定数（適応速度） |
| $\epsilon$ | $10^{-6}$ | — | 数値安定化定数 |
| $\zeta$ | auto | 0.5–2.0 | スケール整合係数 |

**チューニング戦略：**

- **動的範囲が広い環境**：`log_align_enabled=True`, $\tau$を環境変化速度に合わせる
- **高負荷時の破綻防止**：$\alpha_0 \downarrow$で飽和を早める
- **リアルタイム適応**：$\tau \downarrow$で適応を高速化（ただし不安定化リスク）

*数値は目安。ゲーム速度やフレームレートに合わせてスケーリングが必要。*

---

## 12. 次の拡張方向

### 12.1. より複雑な現象への対応

- **多体相互作用**：Hawkes過程による社会的カスケード
- **相転移表示**：ランドウ自由エネルギー $F_S(\phi; p)$ による状態遷移
- **階層構造**：SSD四層（物理・基層・中核・上層）の明示的統合

### 12.2. 応用分野の拡張

- **物語生成**：跳躍 = プロット分岐、整合 = 伏線回収の力学
- **組織学習**：チーム単位での集合的跳躍モデル
- **進化システム**：遺伝的アルゴリズムとの融合

---

## 結論

本ハイブリッドモデルは、SSDの「整合」と「跳躍」を単一の数理フレームワークで統合することに成功しました。

**核心的achievement：**

1. **決定論と確率論の統合**：整合は決定論的、跳躍は確率論的に扱い、両者を自然に接続
2. **対数整合による飽和抑制**：Weber–Fechner則に基づく非線形変換で広範な動的範囲に対応
3. **観測可能な指標**：$E$, $T$, $H(\pi)$, $\alpha_t$ などの KPI により挙動を定量化
4. **実装レディ**：ゲーム AI や教育システムに直接応用可能な軽量設計
5. **拡張性**：個人から社会まで、様々なスケールに適用可能

**v2.0の進化点：**

- **極端な意味圧への対応**：対数整合により、高難易度課題や強刺激での破綻を防止
- **適応的感度調整**：環境の明暗順応のように、入力強度に応じて自動調整
- **スケール不変性**：$\zeta$ パラメータにより、異なるスケールでの整合を統一的に扱える

最も重要なのは、このモデルが「創造性」という予測困難な現象を、**制御可能でありながら驚きも提供する**システムとして実装できる道筋を示したことです。

人間の「ひらめき」も AI の「創発」も、この統一的な数理言語で記述し、設計し、改良していくことが可能になるのです。

---

## 関連概念

- [整合の数理モデル](./整合の数理モデル.md)
- [対数整合対応モデル](./ssd：対数整合対応モデル_v_1_（log_alignment_拡張）.md)
- [整合跳躍数理APIモデル](./整合跳躍数理APIモデル.md)
- [最小整合跳躍数理モデル](./最小整合跳躍数理モデル.md)
